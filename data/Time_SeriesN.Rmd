---
title: "Term Project"
author: "Vikas Vicraman, Hetvi Dave, Nakul Nair"
date: "`r Sys.Date()`"
output:
  rmdformats::html_docco:
    highlight: kate
    toc: true
    toc_depth: 3
---

```{r knitr_init, echo=FALSE, cache=FALSE}
# DO NOT edit this block
knitr::opts_chunk$set(
  cache=TRUE,
  comment=NA,
  message=FALSE,
  warning=FALSE,
  fig.width=12,
  fig.height=7
)
```

#Load in packages
```{r packages, message=FALSE}
if(!require(pacman)) install.packages('pacman')
pacman::p_load(dplyr, locfit, ggplot2, mapproj, readr, ggthemes, viridis, reshape2, cowplot, gstat, sp, automap, data.table, lubridate)
```


# What is the Data?

Our data set contains information on the chemicals released by  a range of industries from 1986 to 2016. While the data is highly nuanced we want to examine chemical release by the petroleum industry in Texas. We have data on the types of chemicals and the medium through which they are released but to begin with, we will examine the total cehmical release. 

To provide further clarification, in our data set, the petroleum industry relates to:

"The Petroleum and Coal Products Manufacturing subsector is based on the transformation of crude petroleum and coal into usable products. The dominant process is petroleum refining that involves the separation of crude petroleum into component products through such techniques as cracking and distillation. In addition, this subsector includes establishments that primarily further process refined petroleum and coal products and produce products, such as asphalt coatings and petroleum lubricating oils."

We intend to relate this to the data on the production of crude oil in Texas, our logic being that it should be a good predictor as more petroleum manufacturing should happen when more petroleum has been extracted and vice versa. 

# Data Exploration

This data set is vast and highly nuanced, in order to approach the analysis methodologically, we start by only considering the most simple variables. Our goal is to examine how the total chemical release varies both by location and by time, attempt to fit a model to this and then test the success.

##Reading in and combining all the data files
```{r read, message=FALSE}
# get the names of the csv files in your current directory
file_names = list.files(pattern = "TRI")  

# for every name you found go and read the csv with that name 
# (this creates a list of files)
import_files = lapply(file_names, read.csv, stringsAsFactors = FALSE)

# append those files one after the other (collapse list elements to one dataset) and save it as d
df = do.call(rbind, import_files)
```

```{r}
head(df)
```


```{r}
dat <- df %>%
  select("YEAR", "LATITUDE","LONGITUDE", "INDUSTRY_SECTOR", "CHEMICAL", "CARCINOGEN", "TOTAL_RELEASES", "UNIT_OF_MEASURE", "CLASSIFICATION") %>%
  filter(INDUSTRY_SECTOR == "Petroleum")

colnames(dat)[colnames(dat)=="LONGITUDE"] <- "lon"
colnames(dat)[colnames(dat)=="LATITUDE"] <- "lat"
names(dat)[1:length(dat)] <- tolower(names(dat)[1:length(dat)])
head(dat)


```


## Energy Dataset

```{r}
#setwd("/Users/Nakul/Documents/Columbia /S2/Env Data Analysis/Final Project/toxicEnvt/")
df2 <- read_csv('Energy.csv') %>%
  setNames(tolower(names(.)))  %>% # variable names are lower case
  filter(year >= "1989" & year < "2017") %>% #Cutting the time series down to the same length as the toxic chemical release data 
  select("year", "crude oil production (mbbl)")
  
colnames(df2)[which(names(df2) == "crude oil production (mbbl)")] <- "oil_mbbl"
energy <- mutate(df2, oil_kg = oil_mbbl*14000)
energy <- energy[seq(dim(energy)[1],1),]
energy

```

## Crude oil production over time

```{r}
ggplot(energy, aes(x = year, y = oil_kg)) +
  geom_point()
```

# Analysis of Chemical Release by Time
```{r}
total_release_time <- dat %>%
  select("year", "total_releases", "unit_of_measure") %>%
  filter(unit_of_measure == "Pounds") %>%    #dioxins measured in grams, excluding these
  group_by(year) %>%
  summarise(release_sum = sum(total_releases * 0.453592))  #converting pounds to kg
tail(total_release_time)

```

## All chemicals released from start to end of data time period
```{r}
ggplot(total_release_time, aes(x = year, y = release_sum)) +
  geom_point()
```
Analysis: Major outlier is financial crisis
Why was it decreasing before the financial crisis
How much of the post 2009 increase is from returning to normal business and how much of it was a genuine increase in petroleum activity.
Remove data from 1986 and 1987

## Remoivng outliers

```{r}
release_time <- total_release_time %>%
  filter(year >= "1989")     #removing huge earlier outliers

ggplot(release_time, aes(x = year, y = release_sum)) +
  geom_point()

```

## Normalizing data and plotting together

```{r}

en <- data.frame(oil_mbbl = energy$oil_mbbl, oil_kg_n = energy$oil_kg/mean(energy$oil_kg), year = release_time$year, release_sum_n = release_time$release_sum/mean(release_time$release_sum))  #joining data into a data frame


melt_en <- melt(en, id = c("year", "oil_mbbl"))   #melting the predictions together
# 
 ggplot(data = melt_en, aes(x = year, y = value)) +
   geom_line(aes(color = variable)) +
   facet_wrap("variable")
  
    #separating plots based on prediction index
```


# Analysis of Chemical Release by Location

```{r}
states <- map_data("state") 
texas <- subset(states, region %in% c("texas"))

texas_map <- ggplot(data = texas) + 
  geom_polygon(aes(x = long, y = lat, group = group), fill = "palegreen", color = "black") + 
  coord_fixed(1.3)
```


```{r}

release_loc <- dat %>%
  select("year", "total_releases", "unit_of_measure", "lon", "lat") %>%
  filter(unit_of_measure == "Pounds" & year >= "1989") %>% 
  
  mutate(total_release = total_releases * 0.453592)  #converting pounds to kg

texas_map + geom_point(aes(x=lon, y = lat, size = total_releases) , data = release_loc) + 
  scale_size_continuous(range=c(3, 10))+ 
  scale_color_viridis() +
  theme_map()
```
Analysis: Map displaying the variability of the total release by location


#Model 1: Autoregression



```{r}
all_reg <- lm(total_releases ~ lat + lon + year, data = dat)
summary(all_reg)
```
From the initial regression, we see that time is the most significant contributor to predict total chemical release.


```{r}
par(mfrow = c(2, 2)) # set up 2 by 2 plot
plot(all_reg) # built-in diagnostic plots
par(mfrow = c(1, 1)) # go back to 1 by 1 plots (default)

```
Clearly, this regression suffers severely form outliers. So the next step would be to remove said outliers.

```{r}
all_reg <- lm(`Toxic Chemical Release in TX` ~ lat + lon + year + `Total Energy Production in TX`, data = en)
summary(all_reg)
```

