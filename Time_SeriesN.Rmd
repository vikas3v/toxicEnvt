---
title: "Term Project"
author: "Vikas Vicraman, Hetvi Dave, Nakul Nair"
date: "`r Sys.Date()`"
output:
  rmdformats::html_docco:
    highlight: kate
    toc: true
    toc_depth: 3
---

```{r knitr_init, echo=FALSE, cache=FALSE}
# DO NOT edit this block
knitr::opts_chunk$set(
  cache=TRUE,
  comment=NA,
  message=FALSE,
  warning=FALSE,
  fig.width=12,
  fig.height=7
)
```

#Load in packages
```{r packages, message=FALSE}
if(!require(pacman)) install.packages('pacman')
pacman::p_load(dplyr, locfit, ggplot2, mapproj, readr, ggthemes, viridis, reshape2, cowplot, gstat, sp, automap, data.table, lubridate)
```

# Data Exploration

This data set is vast and highly nuanced, in order to approach the analysis methodologically, we start by only considering the most simple variables. Our goal is to examine how the total chemical release varies both by location and by time, attempt to fit a model to this and then test the succe

##Reading in and combining all the data files
```{r read, message=FALSE}
# get the names of the csv files in your current directory
file_names = list.files(pattern = "[.]csv$")  

# for every name you found go and read the csv with that name 
# (this creates a list of files)
import_files = lapply(file_names, read.csv, stringsAsFactors = FALSE)

# append those files one after the other (collapse list elements to one dataset) and save it as d
df = do.call(rbind, import_files)

```

```{r}
head(df)
```


```{r}
dat <- df %>%
  select("YEAR", "LATITUDE","LONGITUDE", "INDUSTRY_SECTOR", "CHEMICAL", "CARCINOGEN", "TOTAL_RELEASES", "UNIT_OF_MEASURE", "CLASSIFICATION") %>%
  filter(INDUSTRY_SECTOR == "Petroleum")

colnames(dat)[colnames(dat)=="LONGITUDE"] <- "lon"
colnames(dat)[colnames(dat)=="LATITUDE"] <- "lat"
names(dat)[1:length(dat)] <- tolower(names(dat)[1:length(dat)])
head(dat)
```


## Energy Dataset

```{r}
setwd("/Users/Nakul/Documents/Columbia /S2/Env Data Analysis/Final Project/toxicEnvt/")
df2 <- read_csv('Energy.csv') %>%
  setNames(tolower(names(.))) # variable names are lower case
prod <- as.numeric(df2[43, 12:16])
years <- c(2010, 2011, 2012, 2013, 2014)
energy <- data.frame(prod, years)
energy


```


```{r}
ggplot(energy, aes(x = years, y = prod)) +
  geom_point()
```

# Analysis of Chemical Release by Time
```{r}
total_release_time <- dat %>%
  select("year", "total_releases", "unit_of_measure") %>%
  filter(unit_of_measure == "Pounds") %>%    #dioxins measured in grams, excluding these
  group_by(year) %>%
  summarise(release_sum = sum(total_releases))
total_release_time

```

## All chemicals released from start to end of data time period
```{r}
ggplot(total_release_time, aes(x = year, y = release_sum)) +
  geom_point()
```
Analysis: Major outlier is financial crisis
Figure out when exactly shale gas revolution occurs
Why was it decreasing before the financial crisis
How much of the post 2009 increase is from returning to normal business and how much of it was a genuine increase in petroleum activity.

## Pre 1994 Graph

```{r}
pre_release_time <- dat %>%
  select("year", "total_releases", "unit_of_measure") %>%
  filter(unit_of_measure == "Pounds" & year <= "1994") %>%    #dioxins measured in grams, excluding these
  group_by(year) %>%
  summarise(pre_release_sum = sum(total_releases))

ggplot(pre_release_time, aes(x = year, y = pre_release_sum)) +
  geom_point()

```

## Post 1994 graph
```{r}
pre_release_time <- dat %>%
  select("year", "total_releases", "unit_of_measure") %>%
  filter(unit_of_measure == "Pounds" & year >= "1994") %>%    #dioxins measured in grams, excluding these
  group_by(year) %>%
  summarise(pre_release_sum = sum(total_releases))

ggplot(pre_release_time, aes(x = year, y = pre_release_sum)) +
  geom_point()

```

## Release of dioxin by time
```{r}
dioxin_release_time <- dat %>%
  select("year", "total_releases", "unit_of_measure") %>%
  filter(unit_of_measure == "Grams") %>%    #dioxins measured in grams, excluding these
  group_by(year) %>%
  summarise(dioxin_sum = sum(total_releases))

ggplot(dioxin_release_time, aes(x = year, y = dioxin_sum)) +
  geom_point()
```

## Energy Dataset

```{r}
setwd("/Users/Nakul/Documents/Columbia /S2/Env Data Analysis/Final Project/toxicEnvt/")
df2 <- read_csv('Energy.csv') %>%
  setNames(tolower(names(.))) # variable names are lower case
prod <- as.numeric(df2[43, 12:16])
years <- c(2010, 2011, 2012, 2013, 2014)
energy <- data.frame(prod, years)

```

```{r}

comp <- dat %>%
  select("year", "total_releases", "unit_of_measure", "lon", "lat") %>%
  filter(unit_of_measure == "Pounds" & year >= "2010" & year <= "2014") %>%    #dioxins measured in grams, excluding these
  group_by(year) %>%
  summarise(pre_release_sum = sum(total_releases), lon = mean(lon), lat = mean(lat))

en <- data.frame(energy, comp)  #joining data into a data frame
colnames(en)[which(names(en) == "prod")] <- "Total Energy Production in TX"
colnames(en)[which(names(en) == "pre_release_sum")] <- "Toxic Chemical Release in TX"

melt_en <- melt(en, id = c("year", "years", "lon", "lat"))   #melting the predictions together

ggplot(data = melt_en, aes(x = year, y = value)) +
  geom_point() +
  facet_wrap("variable")
  
    #separating plots based on prediction index
```


# Analysis of Chemical Release by Location

```{r}
states <- map_data("state") 
texas <- subset(states, region %in% c("texas"))

texas_map <- ggplot(data = texas) + 
  geom_polygon(aes(x = long, y = lat, group = group), fill = "palegreen", color = "black") + 
  coord_fixed(1.3)
```


```{r}
texas_map + geom_point(aes(x=lon, y = lat, size = total_releases) , data = dat) + 
  scale_size_continuous(range=c(3, 10))+ 
  scale_color_viridis() +
  theme_map()
```
Analysis: Map displaying the variability of the total release by location


#Model 1: Simple Linear Regression

```{r}
all_reg <- lm(total_releases ~ lat + lon + year, data = dat)
summary(all_reg)
```
From the initial regression, we see that time is the most significant contributor to predict total chemical release.


```{r}
par(mfrow = c(2, 2)) # set up 2 by 2 plot
plot(all_reg) # built-in diagnostic plots
par(mfrow = c(1, 1)) # go back to 1 by 1 plots (default)

```
Clearly, this regression suffers severely form outliers. So the next step would be to remove said outliers.

```{r}
all_reg <- lm(`Toxic Chemical Release in TX` ~ lat + lon + year + `Total Energy Production in TX`, data = en)
summary(all_reg)
```

